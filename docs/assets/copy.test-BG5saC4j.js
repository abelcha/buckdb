const t="import { expect, test } from 'bun:test'\nimport { copy } from './copy'\nimport { from } from '@buckdb/isomorphic'\n\ntest('basic copy to file', async () => {\n    expect(\n        copy(from('duckdb_types()').select()).to('output.parquet', { format: 'parquet' }).toSql({ trim: true })\n    ).toBe(`COPY (FROM duckdb_types() SELECT *) TO 'output.parquet' (FORMAT PARQUET)`)\n})\n\ntest('copy to file with compression', async () => {\n    expect(\n        copy(from('duckdb_types()').select()).to('output_compressed.parquet', { format: 'parquet', compression: 'zstd' }).toSql({ trim: true })\n    ).toBe(`COPY (FROM duckdb_types() SELECT *) TO 'output_compressed.parquet' (FORMAT PARQUET, COMPRESSION ZSTD)`)\n})\n\ntest('copy to S3', async () => {\n    expect(\n        copy(from('duckdb_functions()').select('function_oid', 'function_name')).to('s3://bucket/data.csv', { format: 'csv', header: true }).toSql({ trim: true })\n    ).toBe(`COPY (FROM duckdb_functions() SELECT function_oid, function_name) TO 's3://bucket/data.csv' (FORMAT CSV, HEADER TRUE)`)\n})\n\ntest('direclty from', async () => {\n    expect(\n        from('duckdb_functions()').select('function_oid', 'function_name')\n            .copyTo('s3://bucket/data.csv', { format: 'csv', header: true }).toSql({ trim: true })\n    ).toBe(`COPY (FROM duckdb_functions() SELECT function_oid, function_name) TO 's3://bucket/data.csv' (FORMAT CSV, HEADER TRUE)`)\n})\n\ntest('copy with different format (parquet)', async () => {\n    expect(\n        copy(from('duckdb_types()').select()).to('events.parquet', { field_ids: ['a', 'b'],  compression_level: 5 }).toSql({ trim: true })\n    ).toBe(`COPY (FROM duckdb_types() SELECT *) TO 'events.parquet' (COMPRESSION_LEVEL 5, FIELD_IDS ['a', 'b'])`)\n})\n\ntest('copy with different format (JSON)', async () => {\n    expect(\n        copy(from('duckdb_types()').select()).to('events.json', { format: 'json' }).toSql({ trim: true })\n    ).toBe(`COPY (FROM duckdb_types() SELECT *) TO 'events.json' (FORMAT JSON)`)\n})\n\ntest('copy with partition', async () => {\n    expect(\n        copy(from('duckdb_types()').select()).to('events.json', { format: 'json', partition_by: 'database_name' }).toSql({ trim: true })\n    ).toBe(`COPY (FROM duckdb_types() SELECT *) TO 'events.json' (FORMAT JSON, PARTITION_BY database_name)`)\n})\n\ntest('copy with multiple options', async () => {\n    expect(\n        copy(from('duckdb_types()').select()).to('complex_output.csv', {\n            format: 'csv',\n            compression: 'gzip',\n            delim: ';',\n            header: true,\n        }).toSql({ trim: true })\n    ).toBe(`COPY (FROM duckdb_types() SELECT *) TO 'complex_output.csv' (FORMAT CSV, COMPRESSION GZIP, DELIM ';', HEADER TRUE)`)\n})\n\ntest('copy with numeric and boolean options', async () => {\n    expect(\n        copy(from('duckdb_functions()').select(e => [e.database_name, e.description])).to('numeric_bool.csv', {\n            compression: 'brotli',\n            sqd: true,\n        }).toSql({ trim: true })\n    ).toBe(`COPY (FROM duckdb_functions() SELECT database_name, description) TO 'numeric_bool.csv' (COMPRESSION BROTLI, SQD TRUE)`)\n})\n\n\ntest('real copy', async () => {\n    const q = from('duckdb_types()')\n        .select('logical_type', 'type_oid')\n        .orderBy('type_oid')\n        .limit(2)\n    const resp = await q.copyTo('/tmp/test-copy.csv')\n        .execute()\n    expect(await Bun.file('/tmp/test-copy.csv').text()).toEqual(\n        `logical_type,type_oid\\nNULL,1\\nBOOLEAN,10\\n`)\n    await copy(q).to('/tmp/test-copy.jsonl').execute()\n    expect(await Bun.file('/tmp/test-copy.jsonl').text()).toEqual(`{\"logical_type\":\"NULL\",\"type_oid\":1}\\n{\"logical_type\":\"BOOLEAN\",\"type_oid\":10}\\n`)\n})\n";export{t as default};
